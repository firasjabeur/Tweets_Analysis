{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2c8c8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5398d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.read_csv('train.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "655cf874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>1467836500</td>\n",
       "      <td>Mon Apr 06 22:26:28 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>natalieantipas</td>\n",
       "      <td>so rylee,grace...wana go steve's party or not?? SADLY SINCE ITS EASTER I WNT B ABLE 2 DO MUCH  BUT OHH WELL.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>1467836576</td>\n",
       "      <td>Mon Apr 06 22:26:29 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>timdonnelly</td>\n",
       "      <td>hey, I actually won one of my bracket pools! Too bad it wasn't the one for money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>1467836583</td>\n",
       "      <td>Mon Apr 06 22:26:29 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>homeworld</td>\n",
       "      <td>@stark YOU don't follow me, either  and i work for you!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>1467836859</td>\n",
       "      <td>Mon Apr 06 22:26:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>willy_chaz</td>\n",
       "      <td>A bad nite for the favorite teams: Astros and Spartans lose.  The nite out with T.W. was good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>1467836873</td>\n",
       "      <td>Mon Apr 06 22:26:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LeakySpoon</td>\n",
       "      <td>Body Of Missing Northern Calif. Girl Found: Police have found the remains of a missing Northern California girl .. http://tr.im/imji</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0   0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1   0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2   0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3   0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4   0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       ".. ..         ...                           ...       ...             ...   \n",
       "95  0  1467836500  Mon Apr 06 22:26:28 PDT 2009  NO_QUERY  natalieantipas   \n",
       "96  0  1467836576  Mon Apr 06 22:26:29 PDT 2009  NO_QUERY     timdonnelly   \n",
       "97  0  1467836583  Mon Apr 06 22:26:29 PDT 2009  NO_QUERY       homeworld   \n",
       "98  0  1467836859  Mon Apr 06 22:26:33 PDT 2009  NO_QUERY      willy_chaz   \n",
       "99  0  1467836873  Mon Apr 06 22:26:33 PDT 2009  NO_QUERY      LeakySpoon   \n",
       "\n",
       "                      @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0                         is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!  \n",
       "1                                               @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds  \n",
       "2                                                                                         my whole body feels itchy and like its on fire   \n",
       "3                         @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.   \n",
       "4                                                                                                           @Kwesidei not the whole crew   \n",
       "..                                                                                                                                    ...  \n",
       "95                       so rylee,grace...wana go steve's party or not?? SADLY SINCE ITS EASTER I WNT B ABLE 2 DO MUCH  BUT OHH WELL.....  \n",
       "96                                                      hey, I actually won one of my bracket pools! Too bad it wasn't the one for money   \n",
       "97                                                                                @stark YOU don't follow me, either  and i work for you!  \n",
       "98                                         A bad nite for the favorite teams: Astros and Spartans lose.  The nite out with T.W. was good.  \n",
       "99   Body Of Missing Northern Calif. Girl Found: Police have found the remains of a missing Northern California girl .. http://tr.im/imji  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ef8ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = {\n",
    "    '0': 'target',\n",
    "    '1467810369': 'id',\n",
    "    'Mon Apr 06 22:19:45 PDT 2009': 'date',\n",
    "    'NO_QUERY': 'flag',\n",
    "    '_TheSpecialOne_': 'user',\n",
    "    \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\" : 'text'\n",
    "}\n",
    "\n",
    "# Utilisez la mÃ©thode rename pour renommer les colonnes\n",
    "total_data.rename(columns=new_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ac3829f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "4    800000\n",
       "0    799999\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data.nunique()\n",
    "total_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de9908c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "1    800000\n",
      "0    799999\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x = total_data['text']\n",
    "y = total_data['target'].replace(4,1)\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d5b8270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\n",
      "I just re-pierced my ears \n",
      "@CapnSkulduggery He has pink spots and pink toenails now. Not going to get much done as hubby and Tara are sick today \n",
      "@gemma_kiely what's so awesome about primary? I had a free coffee fr there once &amp; it was kinda crap. I am leaving uni NOW. \n",
      "@innuendogirl Harmony's not a tag-along.  There was an episode where she got minions. Can't remember which one though. :/\n",
      "I need a hug \n",
      "has severe writers block \n",
      "@Melzxoxo WHERE'D U GO LAST NITE? I GOT IN AN ACCIDENT SO THERES NO WAY I CAN MEET U 4 PANCAKES. \n",
      "@roxyreeb You need a new hobby. Wanna train for a triathlon with me? \n",
      "@thecoolestout \n"
     ]
    }
   ],
   "source": [
    "print(x[0])\n",
    "print(x[10])\n",
    "print(x[125000])\n",
    "print(x[123456])\n",
    "print(x[678456])\n",
    "print(x[53])\n",
    "print(x[4563])\n",
    "print(x[25689])\n",
    "print(x[1200000])\n",
    "print(x[1230])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb50f812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted text to lower case.\n",
      "Removed URLs.\n",
      "Removed extra spaces.\n"
     ]
    }
   ],
   "source": [
    "x = x.apply(lambda text: \" \".join(text.lower() for text in str(text).split()))\n",
    "print('Converted text to lower case.')\n",
    "x = x.apply(lambda text: re.sub(r\"http\\S+\", \"\", text))\n",
    "print('Removed URLs.')\n",
    "x = x.apply(lambda text: re.sub(' +', ' ', text))\n",
    "print('Removed extra spaces.')\n",
    "x = x.apply(lambda text: \" \".join([re.sub('[^A-Za-z]+','', text) for text in nltk.word_tokenize(text)]))\n",
    "print('Removed non-alphanumerics.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b357fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contractions(s):\n",
    " s = re.sub(r\"won't\", \"will not\",s)\n",
    " s = re.sub(r\"wouldn't\", \"would not\",s)\n",
    " s = re.sub(r\"couldn't\", \"could not\",s)\n",
    " s = re.sub(r\"\\'d\", \" would\",s)\n",
    " s = re.sub(r\"can\\'t\", \"can not\",s)\n",
    " s = re.sub(r\"n\\'t\", \" not\", s)\n",
    " s = re.sub(r\"\\'nt\", \" not\", s)\n",
    " s= re.sub(r\"\\'re\", \" are\", s)\n",
    " s = re.sub(r\"\\'s\", \" is\", s)\n",
    " s = re.sub(r\"\\'ll\", \" will\", s)\n",
    " s = re.sub(r\"\\'t\", \" not\", s)\n",
    " s = re.sub(r\"\\'ve\", \" have\", s)\n",
    " s = re.sub(r\"\\'m\", \" am\", s)\n",
    " return s\n",
    "x = x.apply(lambda text:contractions(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4b3b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "x = x.apply(lambda text: \" \".join([text for text in text.split() if text not in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a29e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "x = x.apply(lambda text: \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(text)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb05c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ' '.join(x)\n",
    "corpus_tokens = word_tokenize(corpus)\n",
    "frequency_distribution = FreqDist(corpus_tokens)\n",
    "print(len(frequency_distribution.most_common()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2174a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_distribution.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e95eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[0],x[0])\n",
    "print(y[10],x[10])\n",
    "print(y[125000],x[125000])\n",
    "print(y[123456],x[123456])\n",
    "print(y[678456],x[678456])\n",
    "print(y[53],x[53])\n",
    "print(y[4563],x[4563])\n",
    "print(y[25689],x[25689])\n",
    "print(y[1200000],x[1200000])\n",
    "print(y[1230],x[1230])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7583d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to_numpy()\n",
    "y = y.to_numpy()\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.20,random_state=53,stratify=y)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c30c1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldPreprocessor():\n",
    "    def __init__(self,x,y,x_holdout,y_holdout,num_folds):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.x_holdout = x_holdout\n",
    "        self.y_holdout = y_holdout\n",
    "        self.size = y.size\n",
    "        self.num_folds = num_folds\n",
    "        self.folder = KFold(n_splits = num_folds)\n",
    "        self.outer_indices = []\n",
    "        self.nested = False\n",
    "        for i, (train_index, test_index) in enumerate(self.folder.split(self.x)):\n",
    "            self.outer_indices.append([train_index,test_index])\n",
    "    \n",
    "    def preprocess_split(self,fold_index,preprocess_all=False):\n",
    "        raise NotImplementedError\n",
    "            \n",
    "processor = KFoldPreprocessor(x_train,y_train,x_test,y_test,5)\n",
    "print('Length of outer index dimensions')\n",
    "print(len(processor.outer_indices[0][0]))\n",
    "print(len(processor.outer_indices[0][1]))\n",
    "for i in range(0,5):\n",
    "    print(f'First test index of {i}th fold:')\n",
    "    print(processor.outer_indices[i][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0559b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_class(Class):  #@save\n",
    "    \"\"\"Register functions as methods in created class.\"\"\"\n",
    "    def wrapper(obj):\n",
    "        setattr(Class, obj.__name__, obj)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(KFoldPreprocessor)\n",
    "def preprocess_fold(self,fold_index=0,preprocess_all=False,skip_pipeline=False):\n",
    "    pipeline_transformer = Pipeline([\n",
    "        ('vect', CountVectorizer(encoding=encoding,min_df=3)),\n",
    "        ('tfidf', TfidfTransformer())\n",
    "    ])\n",
    "    if skip_pipeline == True:\n",
    "        if preprocess_all == True:\n",
    "            return self.x, self.y, self.x_holdout, self.y_holdout\n",
    "        else:\n",
    "            fold_train_indices = self.outer_indices[fold_index][0]\n",
    "            fold_test_indices = self.outer_indices[fold_index][1]\n",
    "        \n",
    "            fold_x_train_data = [self.x[i] for i in fold_train_indices]\n",
    "            fold_y_train_data = [self.y[i] for i in fold_train_indices]\n",
    "            fold_x_test_data = [self.x[i] for i in fold_test_indices]\n",
    "            fold_y_test_data = [self.y[i] for i in fold_test_indices]\n",
    "        \n",
    "            return fold_x_train_data, fold_y_train_data, fold_x_test_data, fold_y_test_data\n",
    "    \n",
    "    if preprocess_all == True:\n",
    "        preprocessed_x_train_data = pipeline_transformer.fit_transform(self.x)\n",
    "        preprocessed_x_test_data = pipeline_transformer.transform(self.x_holdout)\n",
    "        \n",
    "        return preprocessed_x_train_data, self.y, preprocessed_x_test_data, self.y_holdout\n",
    "    \n",
    "    else:\n",
    "        fold_train_indices = self.outer_indices[fold_index][0]\n",
    "        fold_test_indices = self.outer_indices[fold_index][1]\n",
    "        \n",
    "        fold_x_train_data = [self.x[i] for i in fold_train_indices]\n",
    "        fold_y_train_data = [self.y[i] for i in fold_train_indices]\n",
    "        fold_x_test_data = [self.x[i] for i in fold_test_indices]\n",
    "        fold_y_test_data = [self.y[i] for i in fold_test_indices]\n",
    "        \n",
    "        preprocessed_x_train_data = pipeline_transformer.fit_transform(fold_x_train_data)\n",
    "        preprocessed_x_test_data = pipeline_transformer.transform(fold_x_test_data)\n",
    "        \n",
    "        return preprocessed_x_train_data, fold_y_train_data, preprocessed_x_test_data, fold_y_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b31bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self):\n",
    "        self.train_metrics = []\n",
    "        self.eval_metrics = []\n",
    "        self.set_model()\n",
    "        \n",
    "    def set_hyperparameters(self,hyperparameters):\n",
    "        self.hyperparameters = hyperparameters\n",
    "        \n",
    "    def set_model(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def train_fold(self,x_train,y_train):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def eval_fold(self,trained_model,x_test,y_test,):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def train_model(self,data):\n",
    "        if data.nested == True:\n",
    "            raise NotImplementedError\n",
    "        else:\n",
    "            for i in range(0,len(data.outer_indices)):\n",
    "                print(f'Training fold {i + 1} of {data.num_folds}...')\n",
    "                x_train,y_train,x_test,y_test = data.preprocess_fold(i)\n",
    "                self.train_fold(x_train,y_train)\n",
    "                self.eval_fold(x_test,y_test)\n",
    "            self.train_final_model(data)\n",
    "                \n",
    "    def train_final_model(self,data):\n",
    "        x_train,y_train,x_test,y_test = data.preprocess_fold(preprocess_all=True)\n",
    "        self.train_fold(x_train,y_train)\n",
    "        self.eval_fold(x_test,y_test,final=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14bf23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(Trainer)\n",
    "def set_model(self):\n",
    "    self.set_hyperparameters({'loss':['log_loss'],'penalty':['l2','l1'],'alpha':[0.001,0.003,0.01],'max_iter':[10]})\n",
    "    self.model = SGDClassifier()\n",
    "\n",
    "@add_to_class(Trainer)\n",
    "def train_fold(self,x_train,y_train):\n",
    "    clf = GridSearchCV(self.model, self.hyperparameters,n_jobs=4)\n",
    "    clf.fit(x_train,y_train)\n",
    "    self.trained_model = clf\n",
    "    auc = accuracy_score(y_train,clf.predict(x_train))\n",
    "    self.train_metrics.append(auc)\n",
    "    \n",
    "@add_to_class(Trainer)\n",
    "def eval_fold(self,x_test,y_test,final=False):\n",
    "    predictions = self.trained_model.predict(x_test)\n",
    "    auc = accuracy_score(y_test,predictions)\n",
    "    self.eval_metrics.append(auc)\n",
    "    if final == True:\n",
    "        cm = confusion_matrix(y_test, predictions, labels=[0,1])\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "        disp.plot()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562d4e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = KFoldPreprocessor(x_train,y_train,x_test,y_test,5)\n",
    "trainer = Trainer()\n",
    "trainer.train_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f63f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_train = trainer.train_metrics\n",
    "svm_val = trainer.eval_metrics\n",
    "print(svm_train)\n",
    "print(svm_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b2a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(Trainer)\n",
    "def set_model(self):\n",
    "    self.set_hyperparameters({'fit_prior':[True,False],'force_alpha':[True,False]})\n",
    "    self.model = MultinomialNB()\n",
    "\n",
    "@add_to_class(Trainer)\n",
    "def train_fold(self,x_train,y_train):\n",
    "    clf = GridSearchCV(self.model, self.hyperparameters,n_jobs=4)\n",
    "    clf.fit(x_train,y_train)\n",
    "    self.trained_model = clf\n",
    "    auc = accuracy_score(y_train,clf.predict(x_train))\n",
    "    self.train_metrics.append(auc)\n",
    "    \n",
    "@add_to_class(Trainer)\n",
    "def eval_fold(self,x_test,y_test,final=False):\n",
    "    predictions = self.trained_model.predict(x_test)\n",
    "    auc = accuracy_score(y_test,predictions)\n",
    "    self.eval_metrics.append(auc)\n",
    "    if final == True:\n",
    "        cm = confusion_matrix(y_test, predictions, labels=self.trained_model.classes_)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=self.trained_model.classes_)\n",
    "        disp.plot()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6161deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer()\n",
    "trainer.train_model(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93674a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train = trainer.train_metrics\n",
    "nb_val = trainer.eval_metrics\n",
    "\n",
    "print(nb_train)\n",
    "print(nb_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b881bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(Trainer)\n",
    "def train_model(self,data):\n",
    "        if data.nested == True:\n",
    "            raise NotImplementedError\n",
    "        else:\n",
    "            for i in range(0,len(data.outer_indices)):\n",
    "                print(f'Training fold {i + 1} of {data.num_folds}...')\n",
    "                x_train,y_train,x_test,y_test = data.preprocess_fold(i,skip_pipeline=True)\n",
    "                self.train_fold(x_train,y_train)\n",
    "                self.eval_fold(x_test,y_test)\n",
    "            self.train_final_model(data)\n",
    "\n",
    "@add_to_class(Trainer)\n",
    "def train_final_model(self,data):\n",
    "    x_train,y_train,x_test,y_test = data.preprocess_fold(preprocess_all=True,skip_pipeline=True)\n",
    "    self.train_fold(x_train,y_train)\n",
    "    self.eval_fold(x_test,y_test,final=True)\n",
    "\n",
    "@add_to_class(Trainer)\n",
    "def set_model(self):\n",
    "    self.model = SentimentIntensityAnalyzer()\n",
    "\n",
    "@add_to_class(Trainer)\n",
    "def train_fold(self,x_train,y_train):\n",
    "    self.trained_model = self.model\n",
    "    y_pred = [self.trained_model.polarity_scores(text) for text in x_train]\n",
    "    y_pred = np.array([1 if val.get('pos') > val.get('neg') else 0 for val in y_pred])\n",
    "    auc = accuracy_score(y_train,y_pred)\n",
    "    self.train_metrics.append(auc)\n",
    "    \n",
    "@add_to_class(Trainer)\n",
    "def eval_fold(self,x_test,y_test,final=False):\n",
    "    y_pred = [self.trained_model.polarity_scores(text) for text in x_test]\n",
    "    y_pred = np.array([1 if val.get('pos') > val.get('neg') else 0 for val in y_pred])\n",
    "    auc = accuracy_score(y_test,y_pred)\n",
    "    self.eval_metrics.append(auc)\n",
    "    if final == True:\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "        disp.plot()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f703c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer()\n",
    "trainer.train_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c560e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_train = trainer.train_metrics\n",
    "v_val = trainer.eval_metrics\n",
    "\n",
    "print(v_train)\n",
    "print(v_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a09afdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_avg_train = sum(svc_train[:5])/5\n",
    "svm_avg_val = sum(svc_val[:5])/5\n",
    "svm_test = svc_val[-1]\n",
    "print(f'Average training accuracy for SVM: {svm_avg_train}')\n",
    "print(f'Average validation accuracy for SVM: {svm_avg_val}')\n",
    "print(f'Test accuracy for SVM: {svm_test}\\n')\n",
    "nb_avg_train = sum(nb_train[:5])/5\n",
    "nb_avg_val = sum(nb_val[:5])/5\n",
    "nb_test = nb_val[-1]\n",
    "print(f'Average training accuracy for Naive Bayes: {nb_avg_train}')\n",
    "print(f'Average validation accuracy for Naive Bayes: {nb_avg_val}')\n",
    "print(f'Test accuracy for Naive Bayes: {nb_test}\\n')\n",
    "v_avg_val = sum(v_val[:5])/5\n",
    "v_test = v_val[-1]\n",
    "print(f'Average validation accuracy for Naive Bayes: {v_avg_val}')\n",
    "print(f'Test accuracy for Naive Bayes: {v_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb1ffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train[:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
